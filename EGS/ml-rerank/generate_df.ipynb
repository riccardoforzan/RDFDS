{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "\n",
    "def data_frame_to_html(df):\n",
    "    display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path in which datasets are stored\n",
    "datasets_folder = \"../datasets\"\n",
    "\n",
    "# path of the qrels file\n",
    "qrels_fp = \"qrels.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = sorted(os.listdir(datasets_folder), key=lambda i: int(i))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "edf = pd.DataFrame(\n",
    "    columns=[\n",
    "        \"dataset_id\",\n",
    "        \"size\",\n",
    "        \"extracted_using\",\n",
    "        \"classes\",\n",
    "        \"literals\",\n",
    "        \"entities\",\n",
    "        \"properties\",\n",
    "        \"connections\",\n",
    "        \"connected_vertices\",\n",
    "        \"average_literals_per_vertex\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in datasets:\n",
    "    dataset_base_path = f\"{datasets_folder}/{dataset}\"\n",
    "    metadata_file_path = f\"{dataset_base_path}/metadata.json\"\n",
    "    with open(metadata_file_path, \"r\") as f:\n",
    "        metadata = json.load(f, strict=False)\n",
    "        for e in metadata[\"extracted\"]:\n",
    "\n",
    "            classes_file= f\"{dataset_base_path}/{e['classesFile']}\"\n",
    "            literals_file= f\"{dataset_base_path}/{e['literalsFile']}\"\n",
    "            properties_file= f\"{dataset_base_path}/{e['propertiesFile']}\"\n",
    "            entities_file= f\"{dataset_base_path}/{e['entitiesFile']}\"\n",
    "\n",
    "            classes_count = sum(1 for _ in open(classes_file))\n",
    "            literals_count = sum(1 for _ in open(literals_file))\n",
    "            entities_count = sum(1 for _ in open(entities_file))\n",
    "            properties_count = sum(1 for _ in open(properties_file))\n",
    "\n",
    "            edf.loc[len(edf)] = [\n",
    "                metadata[\"id\"],\n",
    "                e[\"size\"],\n",
    "                e[\"extractedWith\"],\n",
    "                classes_count,\n",
    "                literals_count,\n",
    "                entities_count,\n",
    "                properties_count,\n",
    "                e[\"connections\"],\n",
    "                e[\"connectedVertices\"],\n",
    "                e[\"averageLiteralsPerVertex\"]\n",
    "            ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor dataset in datasets:\\n    dataset_base_path = f\"{datasets_folder}/{dataset}\"\\n    metadata_file_path = f\"{dataset_base_path}/metadata.json\"\\n    with open(metadata_file_path, \"r\") as f:\\n        metadata = json.load(f, strict=False)\\n        for u in metadata[\"unusedFiles\"]:\\n            edf.loc[len(edf)] = [\\n                metadata[\"id\"],\\n                u[\"size\"],\\n                \"ESTIMATED\",\\n                np.nan,\\n                np.nan,\\n                np.nan,\\n                np.nan,\\n                np.nan,\\n                np.nan,\\n                np.nan\\n            ]\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "for dataset in datasets:\n",
    "    dataset_base_path = f\"{datasets_folder}/{dataset}\"\n",
    "    metadata_file_path = f\"{dataset_base_path}/metadata.json\"\n",
    "    with open(metadata_file_path, \"r\") as f:\n",
    "        metadata = json.load(f, strict=False)\n",
    "        for u in metadata[\"unusedFiles\"]:\n",
    "            edf.loc[len(edf)] = [\n",
    "                metadata[\"id\"],\n",
    "                u[\"size\"],\n",
    "                \"ESTIMATED\",\n",
    "                np.nan,\n",
    "                np.nan,\n",
    "                np.nan,\n",
    "                np.nan,\n",
    "                np.nan,\n",
    "                np.nan,\n",
    "                np.nan\n",
    "            ]\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom missforest.miss_forest import MissForest\\nmf = MissForest()\\nres = mf.fit_transform(edf)\\n\\nfrom IPython.core.display import HTML\\n\\ndisplay(HTML(res.to_html()))\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "from missforest.miss_forest import MissForest\n",
    "mf = MissForest()\n",
    "res = mf.fit_transform(edf)\n",
    "\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "display(HTML(res.to_html()))\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add relevance to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf = pd.DataFrame(\n",
    "    columns=[\n",
    "        \"dataset_id\",\n",
    "        \"size\",\n",
    "        \"number_of_classes\",\n",
    "        \"number_of_literals\",\n",
    "        \"number_of_entities\",\n",
    "        \"number_of_properties\",\n",
    "        \"number_of_connections\",\n",
    "        \"number_of_connected_vertices\",\n",
    "        \"average_literals_per_vertex\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the DataFrame by the \"dataset_id\" column\n",
    "grouped = edf.groupby(\"dataset_id\")\n",
    "\n",
    "# Iterate over each group and print the records with the same dataset ID\n",
    "size = 0\n",
    "\n",
    "for dataset_id, group in grouped:\n",
    "    weights = group[\"size\"]\n",
    "    classes = sum(group[\"classes\"])\n",
    "    literals = sum(group[\"literals\"])\n",
    "    entities = sum(group[\"entities\"])\n",
    "    properties = sum(group[\"properties\"])\n",
    "    connections = sum(group[\"connections\"])\n",
    "    connected_vertices = sum(group[\"connected_vertices\"])\n",
    "    average_literals_per_vertex = sum(group[\"average_literals_per_vertex\"])\n",
    "\n",
    "    tdf.loc[len(tdf)] = [\n",
    "        dataset_id,\n",
    "        sum(weights),\n",
    "        classes,\n",
    "        literals,\n",
    "        entities,\n",
    "        properties,\n",
    "        connections,\n",
    "        connected_vertices,\n",
    "        average_literals_per_vertex,\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_frame_to_html(tdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stores: (query_id, list of relevant datasets with their relevance)\n",
    "rank = dict()\n",
    "\n",
    "with open(qrels_fp, \"r\") as qrels_file:\n",
    "    for line in qrels_file:\n",
    "        tokens = line.split()\n",
    "\n",
    "        query_id = tokens[0]\n",
    "        dataset_id = tokens[2]\n",
    "        relevance_val = int(tokens[3])\n",
    "\n",
    "        if relevance_val > 0:\n",
    "\n",
    "            if query_id not in rank.keys():\n",
    "                rank[query_id] = []\n",
    "\n",
    "            rank[query_id].append((dataset_id, relevance_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add to the dataframe a column `relevance_score` that is computed as the sum of all relevance judgement (0,1,2) for that dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevance_scores = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for list in rank.values():\n",
    "    for tuple in list:\n",
    "        dataset_id, relevance_val = tuple\n",
    "\n",
    "        if dataset_id not in relevance_scores:\n",
    "            relevance_scores[dataset_id] = []\n",
    "\n",
    "        relevance_scores[dataset_id].append(int(relevance_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add relevance score to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean\n",
    "\n",
    "tdf[\"relevance\"] = tdf[\"dataset_id\"].map(lambda dataset_id: mean(relevance_scores[dataset_id]) if dataset_id in relevance_scores.keys() else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize relevance scores\n",
    "tdf['relevance'] = (tdf['relevance'] - tdf['relevance'].min()) / (tdf['relevance'].max() - tdf['relevance'].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf.to_csv(\"features.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
