{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all the source files to re rank from the input folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "folder_path = \"dataset-v2-vanilla\"\n",
    "\n",
    "files_to_re_rank = [f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CS-META-ALL-QUERIES-output.txt',\n",
       " 'CS-EXTRACTED-ALL-QUERIES-output.txt',\n",
       " 'LMD-META+EXTRACTED-ALL-QUERIES-output.txt',\n",
       " 'BM25-EXTRACTED-ALL-QUERIES-output.txt',\n",
       " 'LMD-META-ALL-QUERIES-output.txt',\n",
       " 'CS-META+EXTRACTED-ALL-QUERIES-output.txt',\n",
       " 'BM25-META-ALL-QUERIES-output.txt',\n",
       " 'BM25-META+EXTRACTED-ALL-QUERIES-output.txt',\n",
       " 'LMD-EXTRACTED-ALL-QUERIES-output.txt']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_to_re_rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the regressor model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    \"size\",\n",
    "    \"number_of_classes\",\n",
    "    \"number_of_literals\",\n",
    "    \"number_of_entities\",\n",
    "    \"number_of_properties\",\n",
    "    \"number_of_connections\",\n",
    "    \"number_of_connected_vertices\",\n",
    "    \"average_literals_per_vertex\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Load the saved model\n",
    "with open('random_forest_regressor_model.pkl', 'rb') as model:\n",
    "    reg_tree_model = pickle.load(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the features extracted from the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "features_df = pd.read_csv('features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_id</th>\n",
       "      <th>size</th>\n",
       "      <th>number_of_classes</th>\n",
       "      <th>number_of_literals</th>\n",
       "      <th>number_of_entities</th>\n",
       "      <th>number_of_properties</th>\n",
       "      <th>number_of_connections</th>\n",
       "      <th>number_of_connected_vertices</th>\n",
       "      <th>average_literals_per_vertex</th>\n",
       "      <th>relevance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [dataset_id, size, number_of_classes, number_of_literals, number_of_entities, number_of_properties, number_of_connections, number_of_connected_vertices, average_literals_per_vertex, relevance]\n",
       "Index: []"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df[features_df['dataset_id'] == 25054]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read all the rows from each file of the folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def re_rank(rows: list) -> list:\n",
    "\n",
    "    # Calculate new score\n",
    "    new_rank = []\n",
    "\n",
    "    max_score = float(rows[0].split()[4])\n",
    "    \n",
    "    for row in rows:\n",
    "        values = row.split()\n",
    "        dataset_id = int(values[2])\n",
    "        \n",
    "        lucene_score = float(values[4])\n",
    "        fr = features_df[features_df['dataset_id'] == dataset_id]\n",
    "\n",
    "        new_score = 0\n",
    "        predicted_score = 0\n",
    "        if not fr.empty:\n",
    "            predicted_score = reg_tree_model.predict(fr[features])[0]\n",
    "            new_score = (lucene_score/max_score + predicted_score)/2\n",
    "        else:\n",
    "            print(f\"DATASET EMPTY:{dataset_id}\")\n",
    "            new_score = (lucene_score/max_score + predicted_score)\n",
    "\n",
    "        new_rank.append((dataset_id, new_score))\n",
    "    \n",
    "    # Rank based on the new score\n",
    "    new_rank_sorted = sorted(new_rank, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Create the output format\n",
    "    rl = []\n",
    "    index = 1\n",
    "    for dataset_id, new_score in new_rank_sorted:\n",
    "        for e in rows:\n",
    "            values = e.split()\n",
    "            if int(values[2]) == dataset_id:\n",
    "                values[3] = index\n",
    "                values[4] = \"{:.6f}\".format(new_score)\n",
    "                index += 1\n",
    "                rl.append('\\t'.join(map(str, values)))\n",
    "\n",
    "    return rl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def re_rank_file(path: str):\n",
    "    rows_per_query = defaultdict(list)\n",
    "    with open(path, \"r\") as file:\n",
    "        for line in file.readlines():\n",
    "            parts = line.strip().split(\"\\t\")\n",
    "            query_id = int(parts[0])\n",
    "            rows_per_query[query_id].append(line)\n",
    "\n",
    "    re_ranked = []\n",
    "    for _, rows in rows_per_query.items():\n",
    "        re_ranked.append(re_rank(rows))\n",
    "    \n",
    "    return re_ranked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in files_to_re_rank:\n",
    "    path = f\"{folder_path}/{item}\"\n",
    "    re_ranked = re_rank_file(path)\n",
    "\n",
    "    output_path = f\"{folder_path}-re-ranked/{item}\"\n",
    "    with open(output_path, 'w') as file:\n",
    "        for rows in re_ranked:\n",
    "            sr = '\\n'.join(map(str, rows))\n",
    "            file.write(sr + \"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
